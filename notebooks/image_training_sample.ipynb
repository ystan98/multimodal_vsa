{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a23c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5357f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/common/home/projectgrps/IS424/IS424G20/tmp/ipykernel_803689/2282016351.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/common/home/projectgrps/IS424/IS424G20/jupyterlab-venv-pytorch-py311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from classifier import train_and_evaluate, inference, evaluate_validation,  inference, train_and_evaluate, evaluate_validation, prepare_validation_output\n",
    "from classifier import MLP, Model_Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_optimizer import Lookahead\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "seed_value = 0  # You can use any seed value\n",
    "from sklearn.metrics import classification_report\n",
    "# Set seed for CPU\n",
    "import numpy as np\n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# Set seed for GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89802cc9",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad1192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('image_new.csv')\n",
    "del df['Unnamed: 0']\n",
    "df['material_id'] = \"image\" + df.index.astype(str)\n",
    "# df.loc[df['label'].isin(['Gore_Violence', 'horror']), 'label'] = 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446531e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf455426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    7986\n",
       "0    2536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afb086e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(row):\n",
    "    if str(row)=='1':\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56ee05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].apply(update_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0d16af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>temp</th>\n",
       "      <th>label</th>\n",
       "      <th>material_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gorey06ac982080e86f913e1ce19d00970315.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorey0_Terrifier-2.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gorey1.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image temp     label material_id\n",
       "0  gorey06ac982080e86f913e1ce19d00970315.jpg  gor  Negative      image0\n",
       "1                     gorey0_Terrifier-2.jpg  gor  Negative      image1\n",
       "2                                 gorey1.jpg  gor  Negative      image2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0d54cf-356f-4d57-b23d-02d1c7dfce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>temp</th>\n",
       "      <th>label</th>\n",
       "      <th>material_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>pos0 - Copy.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2537</th>\n",
       "      <td>pos0.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>pos00.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image2538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>posb.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>posb21.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>pos_p_sddefault.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image10517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10518</th>\n",
       "      <td>pos_p_sea-cliff-hotel-general-fc98067.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image10518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>pos_p_secret-romantic-date-night-kissing-coupl...</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image10519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10520</th>\n",
       "      <td>pos_p__bkuO7brYtpSveutq5DWqIL2qQJ1Adz6o_9rBeFT...</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image10520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10521</th>\n",
       "      <td>pos_v.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image10521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7986 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image temp     label  \\\n",
       "2536                                     pos0 - Copy.jpg  pos  Positive   \n",
       "2537                                            pos0.jpg  pos  Positive   \n",
       "2538                                           pos00.jpg  pos  Positive   \n",
       "2539                                            posb.jpg  pos  Positive   \n",
       "2540                                          posb21.jpg  pos  Positive   \n",
       "...                                                  ...  ...       ...   \n",
       "10517                                pos_p_sddefault.jpg  pos  Positive   \n",
       "10518          pos_p_sea-cliff-hotel-general-fc98067.jpg  pos  Positive   \n",
       "10519  pos_p_secret-romantic-date-night-kissing-coupl...  pos  Positive   \n",
       "10520  pos_p__bkuO7brYtpSveutq5DWqIL2qQJ1Adz6o_9rBeFT...  pos  Positive   \n",
       "10521                                          pos_v.jpg  pos  Positive   \n",
       "\n",
       "      material_id  \n",
       "2536    image2536  \n",
       "2537    image2537  \n",
       "2538    image2538  \n",
       "2539    image2539  \n",
       "2540    image2540  \n",
       "...           ...  \n",
       "10517  image10517  \n",
       "10518  image10518  \n",
       "10519  image10519  \n",
       "10520  image10520  \n",
       "10521  image10521  \n",
       "\n",
       "[7986 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16dee5d3-5262-4bd0-8773-f42dd44f73f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>temp</th>\n",
       "      <th>label</th>\n",
       "      <th>material_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gorey06ac982080e86f913e1ce19d00970315.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gorey0_Terrifier-2.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gorey1.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gorey1498729.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gorey1lqljQa.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>horror_h_WM-Film-The-Scariest-Moment-from-Ever...</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>horror_h_zEqyD0SBt6HL7W9JQoWwtd5Do1T.jpg</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>horror_h_zombie-horror-monster-blood-face-260n...</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>horror_h_zombie-woman-bloody-face-portrait-hor...</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>horror_h_zombie-woman-with-bloody-face-H8JCT1.jpg</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image2535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2536 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image temp     label  \\\n",
       "0             gorey06ac982080e86f913e1ce19d00970315.jpg  gor  Negative   \n",
       "1                                gorey0_Terrifier-2.jpg  gor  Negative   \n",
       "2                                            gorey1.jpg  gor  Negative   \n",
       "3                                      gorey1498729.jpg  gor  Negative   \n",
       "4                                      gorey1lqljQa.jpg  gor  Negative   \n",
       "...                                                 ...  ...       ...   \n",
       "2531  horror_h_WM-Film-The-Scariest-Moment-from-Ever...  hor  Negative   \n",
       "2532           horror_h_zEqyD0SBt6HL7W9JQoWwtd5Do1T.jpg  hor  Negative   \n",
       "2533  horror_h_zombie-horror-monster-blood-face-260n...  hor  Negative   \n",
       "2534  horror_h_zombie-woman-bloody-face-portrait-hor...  hor  Negative   \n",
       "2535  horror_h_zombie-woman-with-bloody-face-H8JCT1.jpg  hor  Negative   \n",
       "\n",
       "     material_id  \n",
       "0         image0  \n",
       "1         image1  \n",
       "2         image2  \n",
       "3         image3  \n",
       "4         image4  \n",
       "...          ...  \n",
       "2531   image2531  \n",
       "2532   image2532  \n",
       "2533   image2533  \n",
       "2534   image2534  \n",
       "2535   image2535  \n",
       "\n",
       "[2536 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b152d0a-d70e-4e94-9569-78369a35ed51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>temp</th>\n",
       "      <th>label</th>\n",
       "      <th>material_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>horror5992_movie_posters.jpg</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>gore_violence20_train to busan gore scene.jpg</td>\n",
       "      <td>gor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>pos_1497_random human.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image3266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8664</th>\n",
       "      <td>pos_495_random sport.jpg</td>\n",
       "      <td>pos</td>\n",
       "      <td>Positive</td>\n",
       "      <td>image8664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>horror5993_movie_posters.jpg</td>\n",
       "      <td>hor</td>\n",
       "      <td>Negative</td>\n",
       "      <td>image1025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image temp     label material_id\n",
       "1024                   horror5992_movie_posters.jpg  hor  Negative   image1024\n",
       "220   gore_violence20_train to busan gore scene.jpg  gor  Negative    image220\n",
       "3266                      pos_1497_random human.jpg  pos  Positive   image3266\n",
       "8664                       pos_495_random sport.jpg  pos  Positive   image8664\n",
       "1025                   horror5993_movie_posters.jpg  hor  Negative   image1025"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22dca445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label = df.groupby(\"material_id\")[\"label\"].unique().reset_index().rename(columns = {\"label\" : \"label_list\"})\n",
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e18a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "mlb.fit([df[\"label\"].unique().tolist()])\n",
    "\n",
    "df_label = df_label.join(pd.DataFrame.sparse.from_spmatrix(\n",
    "            mlb.transform(df_label.pop('label_list')),\n",
    "            index = df_label.index,\n",
    "            columns = mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f0dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = list(mlb.classes_)\n",
    "unique_labels = sorted([x for x in unique_labels ])\n",
    "one_hot_class_dict = {value: index for index, value in enumerate(unique_labels)}\n",
    "df_label[\"target_encoding\"] = df_label[unique_labels].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c29b5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = list(mlb.classes_)\n",
    "unique_labels = sorted([x for x in unique_labels ])\n",
    "one_hot_class_dict = {value: index for index, value in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc6f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0, 'Positive': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d06962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08a5ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_label(row):\n",
    "    if row['Negative'] == 1:\n",
    "        return 'Negative'\n",
    "    elif row['Positive'] == 1:\n",
    "        return 'Positive'\n",
    "\n",
    "    else:\n",
    "        return None  # or any other default label you prefer\n",
    "\n",
    "df['label'] = df.apply(update_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d73c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 6313\n",
      "Validation set size: 2104\n",
      "Test set size: 2105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, remaining_data = train_test_split(df, test_size=0.4, random_state=42,  stratify=df['label'])\n",
    "\n",
    "validation_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42, stratify=remaining_data['label'])\n",
    "\n",
    "\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(validation_data))\n",
    "print(\"Test set size:\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b198be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>material_id</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>target_encoding</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10517</th>\n",
       "      <td>image9995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10518</th>\n",
       "      <td>image9996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10519</th>\n",
       "      <td>image9997</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10520</th>\n",
       "      <td>image9998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10521</th>\n",
       "      <td>image9999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10522 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      material_id  Negative  Positive target_encoding     label\n",
       "0          image0         1         0          [1, 0]  Negative\n",
       "1          image1         1         0          [1, 0]  Negative\n",
       "2         image10         1         0          [1, 0]  Negative\n",
       "3        image100         1         0          [1, 0]  Negative\n",
       "4       image1000         1         0          [1, 0]  Negative\n",
       "...           ...       ...       ...             ...       ...\n",
       "10517   image9995         0         1          [0, 1]  Positive\n",
       "10518   image9996         0         1          [0, 1]  Positive\n",
       "10519   image9997         0         1          [0, 1]  Positive\n",
       "10520   image9998         0         1          [0, 1]  Positive\n",
       "10521   image9999         0         1          [0, 1]  Positive\n",
       "\n",
       "[10522 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e416e7d6",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "012221be",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 32, \n",
    "          'num_workers':2,  \n",
    "          'shuffle': True}\n",
    "\n",
    "params_inference = {'batch_size': 32, \n",
    "          'num_workers': 2, \n",
    "          'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ccf1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_generator = DataLoader(Model_Dataset(train_data,\n",
    "                              embedding_directory = \"./image_embeddings/\",\n",
    "                              id_column = \"material_id\",\n",
    "                              target = \"target_encoding\",\n",
    "                              return_labels = True),\n",
    "                              **params)\n",
    "\n",
    "val_generator = DataLoader(Model_Dataset(validation_data,\n",
    "                                embedding_directory = \"./image_embeddings/\",\n",
    "                                id_column = \"material_id\",\n",
    "                                target = \"target_encoding\",\n",
    "                                return_labels = True),\n",
    "                                **params_inference)\n",
    "\n",
    "inference_generator = DataLoader(Model_Dataset(test_data,\n",
    "                                embedding_directory = \"./image_embeddings/\",\n",
    "                                id_column = \"material_id\",\n",
    "                                target = \"target_encoding\",\n",
    "                                return_labels = True),\n",
    "                                **params_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489dc677",
   "metadata": {},
   "source": [
    "### Best Model (Focal Loss a=1, g=2 , SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ab6a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.load('./image_embeddings/image0.pt')\n",
    "sample = torch.from_numpy(sample)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b0ff3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from classifier import Model_Dataset\n",
    "from classifier import MLP, train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e279f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "        \"batch_size\" : 32, \n",
    "        \"early_stopping_rounds\": 20,\n",
    "        \"num_workers\":0,\n",
    "        \"max_epochs\" :500,\n",
    "        \"dimensions\" :sample.shape[0],\n",
    "        \"hidden_dim\" :768,\n",
    "        \"learning_rate\" :1e-2,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6dc67c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(dimensions = model_args['dimensions'], hidden_dim = model_args['hidden_dim']\n",
    "                                                , number_of_classes = 2, multilabel_bool=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1831b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=model_args['learning_rate'])\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=model_args['learning_rate'])\n",
    "optimizer = Lookahead(optimizer, k=10, alpha=0.5)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "417e4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "class FocalLoss(nn.Module):\n",
    "    '''\n",
    "    FocalLoss - nn.Module \n",
    "    \n",
    "    Focal loss applies a modulating term to the cross entropy loss in order to focus learning on hard misclassified examples.\n",
    "    It is a dynamically scaled cross entropy loss, where the scaling factor decays to zero as confidence in the correct class increases.\n",
    "    Link - https://paperswithcode.com/method/focal-loss#:~:text=Focal%20loss%20applies%20a%20modulating,in%20the%20correct%20class%20increases.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy(inputs,  targets)\n",
    "        loss = self.alpha * (1 - torch.exp(-bce_loss)) ** self.gamma * bce_loss\n",
    "        return loss\n",
    "\n",
    "criterion = FocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a371e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model_args = {\n",
    "        \"batch_size\" : 32, \n",
    "        \"early_stopping_rounds\": 20,\n",
    "        \"num_workers\":0,\n",
    "        \"max_epochs\" :1000,\n",
    "        \"dimensions\" :sample.shape[0],\n",
    "        \"hidden_dim\" :768,\n",
    "        \"learning_rate\" : 1e-2,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"criterion\": criterion,\n",
    "        \"scaler\":GradScaler()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "42a35f54-ce0d-492e-98c5-cadba880c1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    (1): Dropout(p=0.3, inplace=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (3): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (4): Dropout(p=0.3, inplace=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    (6): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "16f7f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:0.127935 Eval Loss:0.092631:   0%|          | 1/1000 [00:03<1:02:35,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 1 Training Loss:0.127935 Eval Loss:0.092631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Training Loss:0.079299 Eval Loss:0.065365:   0%|          | 2/1000 [00:07<1:04:09,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 2 Training Loss:0.079299 Eval Loss:0.065365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Training Loss:0.058640 Eval Loss:0.048144:   0%|          | 3/1000 [00:11<1:03:29,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 3 Training Loss:0.058640 Eval Loss:0.048144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Training Loss:0.044652 Eval Loss:0.037874:   0%|          | 4/1000 [00:15<1:02:32,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 4 Training Loss:0.044652 Eval Loss:0.037874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Training Loss:0.034503 Eval Loss:0.029172:   0%|          | 5/1000 [00:18<1:02:09,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 5 Training Loss:0.034503 Eval Loss:0.029172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Training Loss:0.027088 Eval Loss:0.021908:   1%|          | 6/1000 [00:22<1:02:48,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 6 Training Loss:0.027088 Eval Loss:0.021908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Training Loss:0.022282 Eval Loss:0.017694:   1%|          | 7/1000 [00:26<1:03:35,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 7 Training Loss:0.022282 Eval Loss:0.017694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Training Loss:0.017545 Eval Loss:0.014309:   1%|          | 8/1000 [00:31<1:06:39,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 8 Training Loss:0.017545 Eval Loss:0.014309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Training Loss:0.014982 Eval Loss:0.012046:   1%|          | 9/1000 [00:35<1:08:17,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 9 Training Loss:0.014982 Eval Loss:0.012046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Training Loss:0.012577 Eval Loss:0.010384:   1%|          | 10/1000 [00:39<1:08:27,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 10 Training Loss:0.012577 Eval Loss:0.010384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11 Training Loss:0.010516 Eval Loss:0.009233:   1%|          | 11/1000 [00:43<1:06:45,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 11 Training Loss:0.010516 Eval Loss:0.009233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12 Training Loss:0.009591 Eval Loss:0.007834:   1%|          | 12/1000 [00:47<1:05:17,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 12 Training Loss:0.009591 Eval Loss:0.007834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13 Training Loss:0.008516 Eval Loss:0.007302:   1%|▏         | 13/1000 [00:51<1:05:10,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 13 Training Loss:0.008516 Eval Loss:0.007302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14 Training Loss:0.007761 Eval Loss:0.006458:   1%|▏         | 14/1000 [00:55<1:06:13,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 14 Training Loss:0.007761 Eval Loss:0.006458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15 Training Loss:0.007017 Eval Loss:0.006173:   2%|▏         | 15/1000 [00:59<1:07:47,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 15 Training Loss:0.007017 Eval Loss:0.006173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16 Training Loss:0.006420 Eval Loss:0.005257:   2%|▏         | 16/1000 [01:03<1:04:07,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 16 Training Loss:0.006420 Eval Loss:0.005257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17 - no improvement005978 Eval Loss:0.005387:   2%|▏         | 16/1000 [01:07<1:04:07,  3.91s/it]\n",
      "Epoch: 17 - no improvement005978 Eval Loss:0.005387:   2%|▏         | 16/1000 [01:07<1:04:07,  3.91s/it]\n",
      "Epoch: 18 Training Loss:0.005677 Eval Loss:0.004858:   2%|▏         | 18/1000 [01:10<1:03:41,  3.89s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 18 Training Loss:0.005677 Eval Loss:0.004858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Training Loss:0.005394 Eval Loss:0.004695:   2%|▏         | 19/1000 [01:15<1:06:17,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 19 Training Loss:0.005394 Eval Loss:0.004695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Training Loss:0.005097 Eval Loss:0.004245:   2%|▏         | 20/1000 [01:19<1:04:15,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 20 Training Loss:0.005097 Eval Loss:0.004245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 21 Training Loss:0.005087 Eval Loss:0.004143:   2%|▏         | 21/1000 [01:23<1:05:11,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 21 Training Loss:0.005087 Eval Loss:0.004143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 22 - no improvement004836 Eval Loss:0.004313:   2%|▏         | 21/1000 [01:27<1:05:11,  4.00s/it]\n",
      "Epoch: 22 - no improvement004836 Eval Loss:0.004313:   2%|▏         | 21/1000 [01:27<1:05:11,  4.00s/it]\n",
      "Epoch: 23 Training Loss:0.004464 Eval Loss:0.003794:   2%|▏         | 23/1000 [01:31<1:09:21,  4.26s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 23 Training Loss:0.004464 Eval Loss:0.003794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 24 - no improvement004195 Eval Loss:0.004027:   2%|▏         | 23/1000 [01:38<1:09:21,  4.26s/it]\n",
      "Epoch: 24 - no improvement004195 Eval Loss:0.004027:   2%|▏         | 23/1000 [01:38<1:09:21,  4.26s/it]\n",
      "Epoch: 25 Training Loss:0.004091 Eval Loss:0.003756:   2%|▎         | 25/1000 [01:45<1:28:40,  5.46s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 25 Training Loss:0.004091 Eval Loss:0.003756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 26 Training Loss:0.003826 Eval Loss:0.003209:   3%|▎         | 26/1000 [01:51<1:32:17,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 26 Training Loss:0.003826 Eval Loss:0.003209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 27 - no improvement004114 Eval Loss:0.003690:   3%|▎         | 26/1000 [01:58<1:32:17,  5.69s/it]\n",
      "Epoch: 27 - no improvement004114 Eval Loss:0.003690:   3%|▎         | 26/1000 [01:58<1:32:17,  5.69s/it]\n",
      "Epoch: 28 - no improvement004063 Eval Loss:0.003263:   3%|▎         | 27/1000 [02:03<1:36:30,  5.95s/it]                           \n",
      "Epoch: 28 - no improvement004063 Eval Loss:0.003263:   3%|▎         | 27/1000 [02:03<1:36:30,  5.95s/it]\n",
      "Epoch: 29 - no improvement004021 Eval Loss:0.003265:   3%|▎         | 28/1000 [02:09<1:32:23,  5.70s/it]                           \n",
      "Epoch: 29 - no improvement004021 Eval Loss:0.003265:   3%|▎         | 28/1000 [02:09<1:32:23,  5.70s/it]\n",
      "Epoch: 30 - no improvement003596 Eval Loss:0.003266:   3%|▎         | 29/1000 [02:15<1:34:40,  5.85s/it]                           \n",
      "Epoch: 30 - no improvement003596 Eval Loss:0.003266:   3%|▎         | 29/1000 [02:15<1:34:40,  5.85s/it]\n",
      "Epoch: 31 Training Loss:0.003684 Eval Loss:0.003003:   3%|▎         | 31/1000 [02:20<1:33:38,  5.80s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 31 Training Loss:0.003684 Eval Loss:0.003003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 32 - no improvement003736 Eval Loss:0.003156:   3%|▎         | 31/1000 [02:27<1:33:38,  5.80s/it]\n",
      "Epoch: 32 - no improvement003736 Eval Loss:0.003156:   3%|▎         | 31/1000 [02:27<1:33:38,  5.80s/it]\n",
      "Epoch: 33 Training Loss:0.003319 Eval Loss:0.002862:   3%|▎         | 33/1000 [02:32<1:32:00,  5.71s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 33 Training Loss:0.003319 Eval Loss:0.002862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 34 Training Loss:0.003503 Eval Loss:0.002775:   3%|▎         | 34/1000 [02:38<1:35:08,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 34 Training Loss:0.003503 Eval Loss:0.002775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 35 - no improvement003252 Eval Loss:0.003104:   3%|▎         | 34/1000 [02:44<1:35:08,  5.91s/it]\n",
      "Epoch: 35 - no improvement003252 Eval Loss:0.003104:   3%|▎         | 34/1000 [02:44<1:35:08,  5.91s/it]\n",
      "Epoch: 36 - no improvement003250 Eval Loss:0.002793:   4%|▎         | 35/1000 [02:51<1:36:16,  5.99s/it]                           \n",
      "Epoch: 36 - no improvement003250 Eval Loss:0.002793:   4%|▎         | 35/1000 [02:51<1:36:16,  5.99s/it]\n",
      "Epoch: 37 Training Loss:0.003142 Eval Loss:0.002720:   4%|▎         | 37/1000 [02:57<1:38:23,  6.13s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 37 Training Loss:0.003142 Eval Loss:0.002720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 38 Training Loss:0.003229 Eval Loss:0.002533:   4%|▍         | 38/1000 [03:04<1:41:40,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 38 Training Loss:0.003229 Eval Loss:0.002533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 39 - no improvement003039 Eval Loss:0.002845:   4%|▍         | 38/1000 [03:10<1:41:40,  6.34s/it]\n",
      "Epoch: 39 - no improvement003039 Eval Loss:0.002845:   4%|▍         | 38/1000 [03:10<1:41:40,  6.34s/it]\n",
      "Epoch: 40 Training Loss:0.003217 Eval Loss:0.002524:   4%|▍         | 40/1000 [03:16<1:40:48,  6.30s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 40 Training Loss:0.003217 Eval Loss:0.002524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 41 - no improvement002958 Eval Loss:0.002530:   4%|▍         | 40/1000 [03:22<1:40:48,  6.30s/it]\n",
      "Epoch: 41 - no improvement002958 Eval Loss:0.002530:   4%|▍         | 40/1000 [03:22<1:40:48,  6.30s/it]\n",
      "Epoch: 42 - no improvement003003 Eval Loss:0.002842:   4%|▍         | 41/1000 [03:27<1:39:38,  6.23s/it]                           \n",
      "Epoch: 42 - no improvement003003 Eval Loss:0.002842:   4%|▍         | 41/1000 [03:27<1:39:38,  6.23s/it]\n",
      "Epoch: 43 - no improvement003107 Eval Loss:0.002581:   4%|▍         | 42/1000 [03:33<1:33:34,  5.86s/it]                           \n",
      "Epoch: 43 - no improvement003107 Eval Loss:0.002581:   4%|▍         | 42/1000 [03:33<1:33:34,  5.86s/it]\n",
      "Epoch: 44 - no improvement002983 Eval Loss:0.002528:   4%|▍         | 43/1000 [03:40<1:32:43,  5.81s/it]                           \n",
      "Epoch: 44 - no improvement002983 Eval Loss:0.002528:   4%|▍         | 43/1000 [03:40<1:32:43,  5.81s/it]\n",
      "Epoch: 45 - no improvement003043 Eval Loss:0.002723:   4%|▍         | 44/1000 [03:47<1:39:35,  6.25s/it]                           \n",
      "Epoch: 45 - no improvement003043 Eval Loss:0.002723:   4%|▍         | 44/1000 [03:47<1:39:35,  6.25s/it]\n",
      "Epoch: 46 - no improvement002710 Eval Loss:0.002721:   4%|▍         | 45/1000 [03:53<1:40:49,  6.33s/it]                           \n",
      "Epoch: 46 - no improvement002710 Eval Loss:0.002721:   4%|▍         | 45/1000 [03:53<1:40:49,  6.33s/it]\n",
      "Epoch: 46 Training Loss:0.002710 Eval Loss:0.002721:   5%|▍         | 46/1000 [03:53<1:40:33,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046: reducing learning rate of group 0 to 1.0000e-03.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 47 Training Loss:0.002789 Eval Loss:0.002516:   5%|▍         | 47/1000 [04:00<1:40:02,  6.30s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 47 Training Loss:0.002789 Eval Loss:0.002516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 48 - no improvement003018 Eval Loss:0.002640:   5%|▍         | 47/1000 [04:06<1:40:02,  6.30s/it]\n",
      "Epoch: 48 - no improvement003018 Eval Loss:0.002640:   5%|▍         | 47/1000 [04:06<1:40:02,  6.30s/it]\n",
      "Epoch: 49 Training Loss:0.002714 Eval Loss:0.002231:   5%|▍         | 49/1000 [04:13<1:43:23,  6.52s/it]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a better loss!\n",
      "Epoch: 49 Training Loss:0.002714 Eval Loss:0.002231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 50 - no improvement003013 Eval Loss:0.002811:   5%|▍         | 49/1000 [04:19<1:43:23,  6.52s/it]\n",
      "Epoch: 50 - no improvement003013 Eval Loss:0.002811:   5%|▍         | 49/1000 [04:19<1:43:23,  6.52s/it]\n",
      "Epoch: 51 - no improvement002763 Eval Loss:0.002469:   5%|▌         | 50/1000 [04:25<1:42:18,  6.46s/it]                           \n",
      "Epoch: 51 - no improvement002763 Eval Loss:0.002469:   5%|▌         | 50/1000 [04:25<1:42:18,  6.46s/it]\n",
      "Epoch: 52 - no improvement002699 Eval Loss:0.002726:   5%|▌         | 51/1000 [04:32<1:40:42,  6.37s/it]                           \n",
      "Epoch: 52 - no improvement002699 Eval Loss:0.002726:   5%|▌         | 51/1000 [04:32<1:40:42,  6.37s/it]\n",
      "Epoch: 53 - no improvement002764 Eval Loss:0.002374:   5%|▌         | 52/1000 [04:38<1:41:22,  6.42s/it]                           \n",
      "Epoch: 53 - no improvement002764 Eval Loss:0.002374:   5%|▌         | 52/1000 [04:38<1:41:22,  6.42s/it]\n",
      "Epoch: 54 - no improvement002670 Eval Loss:0.002518:   5%|▌         | 53/1000 [04:44<1:41:01,  6.40s/it]                           \n",
      "Epoch: 54 - no improvement002670 Eval Loss:0.002518:   5%|▌         | 53/1000 [04:44<1:41:01,  6.40s/it]\n",
      "Epoch: 55 - no improvement002786 Eval Loss:0.002335:   5%|▌         | 54/1000 [04:51<1:38:27,  6.24s/it]                           \n",
      "Epoch: 55 - no improvement002786 Eval Loss:0.002335:   5%|▌         | 54/1000 [04:51<1:38:27,  6.24s/it]\n",
      "Epoch: 55 Training Loss:0.002786 Eval Loss:0.002335:   6%|▌         | 55/1000 [04:51<1:39:04,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00055: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 56 - no improvement002709 Eval Loss:0.002580:   6%|▌         | 55/1000 [04:58<1:39:04,  6.29s/it]                           \n",
      "Epoch: 56 - no improvement002709 Eval Loss:0.002580:   6%|▌         | 55/1000 [04:58<1:39:04,  6.29s/it]\n",
      "Epoch: 57 - no improvement002928 Eval Loss:0.003033:   6%|▌         | 56/1000 [05:04<1:41:56,  6.48s/it]                           \n",
      "Epoch: 57 - no improvement002928 Eval Loss:0.003033:   6%|▌         | 56/1000 [05:04<1:41:56,  6.48s/it]\n",
      "Epoch: 58 - no improvement003467 Eval Loss:0.002792:   6%|▌         | 57/1000 [05:10<1:41:44,  6.47s/it]                           \n",
      "Epoch: 58 - no improvement003467 Eval Loss:0.002792:   6%|▌         | 57/1000 [05:10<1:41:44,  6.47s/it]\n",
      "Epoch: 59 - no improvement002804 Eval Loss:0.002276:   6%|▌         | 58/1000 [05:16<1:40:53,  6.43s/it]                           \n",
      "Epoch: 59 - no improvement002804 Eval Loss:0.002276:   6%|▌         | 58/1000 [05:16<1:40:53,  6.43s/it]\n",
      "Epoch: 60 - no improvement002747 Eval Loss:0.002482:   6%|▌         | 59/1000 [05:22<1:38:41,  6.29s/it]                           \n",
      "Epoch: 60 - no improvement002747 Eval Loss:0.002482:   6%|▌         | 59/1000 [05:22<1:38:41,  6.29s/it]\n",
      "Epoch: 61 - no improvement002798 Eval Loss:0.002779:   6%|▌         | 60/1000 [05:28<1:35:18,  6.08s/it]                           \n",
      "Epoch: 61 - no improvement002798 Eval Loss:0.002779:   6%|▌         | 60/1000 [05:28<1:35:18,  6.08s/it]\n",
      "Epoch: 61 Training Loss:0.002798 Eval Loss:0.002779:   6%|▌         | 61/1000 [05:28<1:35:51,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00061: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 62 - no improvement002866 Eval Loss:0.002544:   6%|▌         | 61/1000 [05:35<1:35:51,  6.13s/it]                           \n",
      "Epoch: 62 - no improvement002866 Eval Loss:0.002544:   6%|▌         | 61/1000 [05:35<1:35:51,  6.13s/it]\n",
      "Epoch: 63 - no improvement002809 Eval Loss:0.002496:   6%|▌         | 62/1000 [05:41<1:41:19,  6.48s/it]                           \n",
      "Epoch: 63 - no improvement002809 Eval Loss:0.002496:   6%|▌         | 62/1000 [05:41<1:41:19,  6.48s/it]\n",
      "Epoch: 64 - no improvement002751 Eval Loss:0.002576:   6%|▋         | 63/1000 [05:47<1:38:49,  6.33s/it]                           \n",
      "Epoch: 64 - no improvement002751 Eval Loss:0.002576:   6%|▋         | 63/1000 [05:47<1:38:49,  6.33s/it]\n",
      "Epoch: 65 - no improvement002982 Eval Loss:0.002528:   6%|▋         | 64/1000 [05:53<1:34:48,  6.08s/it]                           \n",
      "Epoch: 65 - no improvement002982 Eval Loss:0.002528:   6%|▋         | 64/1000 [05:53<1:34:48,  6.08s/it]\n",
      "Epoch: 66 - no improvement002733 Eval Loss:0.002633:   6%|▋         | 65/1000 [05:59<1:34:35,  6.07s/it]                           \n",
      "Epoch: 66 - no improvement002733 Eval Loss:0.002633:   6%|▋         | 65/1000 [05:59<1:34:35,  6.07s/it]\n",
      "Epoch: 67 - no improvement002884 Eval Loss:0.002649:   7%|▋         | 66/1000 [06:06<1:36:27,  6.20s/it]                           \n",
      "Epoch: 67 - no improvement002884 Eval Loss:0.002649:   7%|▋         | 66/1000 [06:06<1:36:27,  6.20s/it]\n",
      "Epoch: 67 Training Loss:0.002884 Eval Loss:0.002649:   7%|▋         | 67/1000 [06:06<1:35:55,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 68 - no improvement002964 Eval Loss:0.002741:   7%|▋         | 67/1000 [06:12<1:35:55,  6.17s/it]                           \n",
      "Epoch: 68 - no improvement002964 Eval Loss:0.002741:   7%|▋         | 67/1000 [06:12<1:35:55,  6.17s/it]\n",
      "Epoch: 69 - no improvement002692 Eval Loss:0.002342:   7%|▋         | 68/1000 [06:17<1:35:49,  6.17s/it]                           \n",
      "Epoch: 69 - no improvement002692 Eval Loss:0.002342:   7%|▋         | 68/1000 [06:17<1:35:49,  6.17s/it]\n",
      "Epoch: 69 Training Loss:0.002692 Eval Loss:0.002342:   7%|▋         | 68/1000 [06:17<1:26:18,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in over 20 epochs, early break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model, criterion, training_losses, eval_losses = train_and_evaluate(model,\n",
    "                                                                         train_generator,\n",
    "                                                                         val_generator,\n",
    "                                                                         updated_model_args,\n",
    "                                                                         device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8f2e536",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions, val_truths = inference(val_generator,\n",
    "                                        best_model,\n",
    "                                        criterion,\n",
    "                                        device,\n",
    "                                        validation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "015bd347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.94      0.93       507\n",
      "    Positive       0.98      0.97      0.98      1597\n",
      "\n",
      "    accuracy                           0.96      2104\n",
      "   macro avg       0.95      0.96      0.95      2104\n",
      "weighted avg       0.96      0.96      0.96      2104\n",
      "\n",
      "Threshold chosen 0.6\n"
     ]
    }
   ],
   "source": [
    "prediction_array_res, classification_report_dict, threshold_chosen = evaluate_validation(val_predictions,\n",
    "                                                                                    val_truths,\n",
    "                                                                                    one_hot_class_dict,\n",
    "                                                                                    num_of_class = 2,\n",
    "                                                                                    multilabel_bool = False)\n",
    "print('Threshold chosen',round(threshold_chosen,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "457c14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "def evaluate_validation(predictions, truths, one_hot_class_dict, multilabel_bool, num_of_class):\n",
    "    \n",
    "    if multilabel_bool:\n",
    "        prediction_thresh = torch.tensor(np.where(predictions >= threshold_chosen, 1, 0))\n",
    "        class_report_dict = classification_report(truths, prediction_thresh, target_names= one_hot_class_dict.keys(), output_dict = True)\n",
    "        print(classification_report(truths, prediction_thresh, target_names= one_hot_class_dict.keys()))\n",
    "        return prediction_thresh.numpy(), class_report_dict, threshold_chosen\n",
    "    \n",
    "    else:\n",
    "        if num_of_class ==2:\n",
    "            #binary\n",
    "            indices = np.where(truths == 1)\n",
    "            indices = indices[1]\n",
    "            pred = predictions[:, 1]\n",
    "\n",
    "            predictions_thresh = torch.tensor(np.where(pred >= 0.5, 1, 0))\n",
    "            class_report_dict = classification_report(indices, predictions_thresh, target_names= one_hot_class_dict.keys(), output_dict = True)\n",
    "            print(classification_report(indices, predictions_thresh, target_names= one_hot_class_dict.keys()))     \n",
    "            return predictions_thresh.numpy(), class_report_dict, threshold_chosen\n",
    "        \n",
    "            \n",
    "        else: \n",
    "            prediction_array_argmax = torch.argmax(torch.tensor(predictions), dim = 1)\n",
    "            prediction_array_res = torch.zeros_like(torch.tensor(predictions)).scatter_(1, prediction_array_argmax.unsqueeze(1), 1.)\n",
    "            class_report_dict = classification_report(truths, prediction_array_res, target_names= one_hot_class_dict.keys(), output_dict = True)\n",
    "            print(classification_report(truths, prediction_array_res, target_names= one_hot_class_dict.keys()))\n",
    "\n",
    "            return prediction_array_res.numpy(), class_report_dict, threshold_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f60b12ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.94      0.93       507\n",
      "    Positive       0.98      0.97      0.98      1598\n",
      "\n",
      "    accuracy                           0.96      2105\n",
      "   macro avg       0.95      0.96      0.95      2105\n",
      "weighted avg       0.96      0.96      0.96      2105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inf_predictions, inf_truths = inference(inference_generator,\n",
    "                                        best_model,\n",
    "                                        criterion,\n",
    "                                        device,\n",
    "                                        validation = True)\n",
    "\n",
    "prediction_array_res, classification_report_dict, threshold_chosen = evaluate_validation(inf_predictions,\n",
    "                                                                                    inf_truths,\n",
    "                                                                                    one_hot_class_dict,\n",
    "                                                                                    False, num_of_class = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
